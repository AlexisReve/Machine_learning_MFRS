{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.models as models\n",
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  \n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  \n",
    "])\n",
    "\n",
    "def transform_triplet(triplet_list, batch_size=256, apply_transform=True):\n",
    "    batch_steps = len(triplet_list) // batch_size\n",
    "    \n",
    "    for i in range(batch_steps + 1):\n",
    "        anchor, positive, negative = [], [], []\n",
    "\n",
    "        j = i * batch_size\n",
    "        while j < (i + 1) * batch_size and j < len(triplet_list):\n",
    "            a, p, n = triplet_list[j]\n",
    "            a_img = read_image(a)\n",
    "            p_img = read_image(p)\n",
    "            n_img = read_image(n)\n",
    "\n",
    "            if a_img is not None and p_img is not None and n_img is not None:\n",
    "                if apply_transform:\n",
    "                    a_img = transform(a_img)\n",
    "                    p_img = transform(p_img)\n",
    "                    n_img = transform(n_img)\n",
    "\n",
    "                anchor.append(a_img)\n",
    "                positive.append(p_img)\n",
    "                negative.append(n_img)\n",
    "            j += 1\n",
    "\n",
    "        if not anchor or not positive or not negative:\n",
    "            continue  \n",
    "\n",
    "        \n",
    "        anchor = torch.stack(anchor)\n",
    "        positive = torch.stack(positive)\n",
    "        negative = torch.stack(negative)\n",
    "\n",
    "        yield ([anchor, positive, negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training list: 1062\n",
      "Length of testing list : 266\n",
      "\n",
      "Test List: {'1514': 2, '1604': 3, '1640': 13, '966': 2, '326': 2, '1016': 6, '440': 2, '1084': 3, '492': 2, '459': 2, '1122': 2, '1408': 2, '1676': 9, '553': 8, '65': 2, '797': 3, '732': 4, '0': 4, '1138': 3, '1218': 2, '1232': 2, '1436': 4, '1180': 3, '419': 2, '502': 2, '604': 3, '807': 5, '803': 4, '1074': 4, '1185': 2, '1183': 3, '337': 3, '1070': 2, '722': 4, '684': 2, '1492': 2, '1163': 3, '233': 2, '317': 2, '1340': 2, '281': 4, '851': 16, '533': 2, '120': 2, '545': 3, '184': 3, '696': 2, '1553': 2, '1313': 3, '1652': 21, '1671': 4, '1526': 3, '1097': 6, '293': 2, '1024': 8, '1398': 6, '1380': 6, '1150': 8, '177': 2, '563': 2, '623': 2, '1137': 4, '1260': 2, '1266': 4, '1099': 3, '744': 2, '932': 2, '96': 3, '630': 2, '26': 2, '473': 7, '1418': 2, '361': 3, '328': 3, '897': 7, '1519': 2, '1263': 2, '1164': 2, '1674': 2, '982': 2, '785': 3, '460': 3, '520': 9, '743': 2, '335': 2, '1413': 3, '1461': 4, '1267': 4, '1606': 2, '47': 3, '1561': 2, '1627': 2, '206': 2, '1088': 14, '1532': 2, '535': 2, '1369': 2, '734': 5, '608': 4, '497': 3, '1338': 6, '1490': 24, '422': 4, '1320': 2, '1250': 3, '214': 6, '181': 2, '1649': 2, '1504': 2, '1246': 16, '1535': 9, '918': 2, '1502': 2, '868': 7, '1323': 2, '687': 2, '21': 3, '1119': 2, '58': 3, '1115': 2, '967': 13, '1143': 2, '1108': 13, '644': 2, '933': 4, '1177': 4, '1040': 2, '828': 3, '1107': 3, '36': 2, '663': 2, '396': 2, '1254': 7, '986': 11, '421': 2, '249': 8, '1247': 11, '959': 2, '1019': 2, '706': 2, '795': 2, '1307': 4, '1494': 4, '1095': 5, '633': 3, '1193': 2, '126': 2, '1549': 3, '990': 4, '1190': 5, '1277': 3, '1428': 2, '1625': 2, '532': 2, '863': 5, '527': 2, '1496': 4, '415': 2, '769': 2, '1157': 2, '368': 4, '1597': 11, '1451': 3, '444': 3, '354': 3, '378': 11, '138': 2, '373': 6, '1343': 7, '487': 2, '1075': 7, '653': 2, '1431': 2, '1391': 3, '191': 2, '1379': 2, '1683': 7, '1570': 2, '267': 2, '669': 2, '1608': 4, '1111': 2, '790': 2, '1221': 4, '538': 2, '597': 2, '1542': 2, '46': 2, '50': 2, '1062': 2, '564': 2, '1636': 2, '1240': 2, '798': 2, '1302': 2, '1383': 2, '231': 2, '1531': 7, '574': 3, '800': 14, '589': 3, '1055': 5, '314': 3, '908': 14, '350': 10, '374': 3, '1600': 2, '1642': 3, '1046': 2, '1419': 5, '968': 2, '306': 9, '924': 3, '1576': 5, '386': 6, '90': 4, '1407': 28, '57': 3, '75': 8, '197': 2, '1599': 3, '176': 2, '858': 7, '1289': 2, '1309': 4, '856': 33, '1073': 3, '8': 4, '1565': 5, '1101': 2, '695': 3, '1361': 2, '338': 27, '763': 2, '1513': 5, '483': 2, '1181': 6, '319': 2, '917': 3, '1387': 5, '709': 37, '275': 3, '199': 2, '490': 5, '1682': 6, '1602': 2, '668': 4, '336': 3, '718': 18, '124': 2, '829': 2, '404': 2, '351': 2, '1021': 3, '1341': 2, '1497': 16, '610': 4, '844': 6, '1059': 2, '915': 5, '814': 2, '739': 2, '654': 31, '332': 2, '1072': 3, '1414': 7}\n"
     ]
    }
   ],
   "source": [
    "random.seed(5)\n",
    "np.random.seed(5)\n",
    "\n",
    "\n",
    "ROOT = \"Extracted Faces\"\n",
    "\n",
    "train_list, test_list = train_test_split(ROOT, split=0.8)\n",
    "print(\"Length of training list:\", len(train_list))\n",
    "print(\"Length of testing list :\", len(test_list))\n",
    "print(\"\\nTest List:\", test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training triplets: 9074\n",
      "Number of testing triplets : 2218\n",
      "\n",
      "Examples of triplets:\n",
      "(('571', '5.jpg'), ('571', '6.jpg'), ('1282', '1.jpg'))\n",
      "(('841', '5.jpg'), ('841', '9.jpg'), ('1662', '3.jpg'))\n",
      "(('536', '0.jpg'), ('536', '6.jpg'), ('865', '0.jpg'))\n",
      "(('38', '5.jpg'), ('38', '9.jpg'), ('1511', '1.jpg'))\n",
      "(('1098', '4.jpg'), ('1098', '5.jpg'), ('366', '3.jpg'))\n"
     ]
    }
   ],
   "source": [
    "train_triplet = generate_triplet(ROOT, train_list)\n",
    "test_triplet  = generate_triplet(ROOT, test_list)\n",
    "\n",
    "print(\"Number of training triplets:\", len(train_triplet))\n",
    "print(\"Number of testing triplets :\", len(test_triplet))\n",
    "\n",
    "print(\"\\nExamples of triplets:\")\n",
    "for i in range(5):\n",
    "    print(train_triplet[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexisrevelle/miniconda3/envs/data-science/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/alexisrevelle/miniconda3/envs/data-science/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "encoder = load_pretrained_model(input_shape=(3, 128, 128))\n",
    "siamese_network = SiameseNetwork(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = SiameseModel(siamese_network)\n",
    "optimizer = optim.Adam(siamese_model.parameters(), lr=1e-3, eps=1e-01)\n",
    "\n",
    "def triplet_loss(ap_distance, an_distance):\n",
    "    loss = ap_distance - an_distance + 0.5\n",
    "    loss = torch.max(loss, torch.zeros_like(loss))  \n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcc4d3209524ae3a957061867e53630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 1 \t (Epoch done in 3209 sec)\n",
      "Loss on train    = 0.12770\n",
      "Accuracy on test = 0.72858\n",
      "\n",
      "EPOCH: 2 \t (Epoch done in 3289 sec)\n",
      "Loss on train    = 0.05792\n",
      "Accuracy on test = 0.75924\n",
      "\n",
      "EPOCH: 3 \t (Epoch done in 3195 sec)\n",
      "Loss on train    = 0.02653\n",
      "Accuracy on test = 0.77277\n",
      "\n",
      "EPOCH: 4 \t (Epoch done in 3099 sec)\n",
      "Loss on train    = 0.01113\n",
      "Accuracy on test = 0.76150\n",
      "\n",
      "EPOCH: 5 \t (Epoch done in 3096 sec)\n",
      "Loss on train    = 0.00425\n",
      "Accuracy on test = 0.76240\n",
      "\n",
      "EPOCH: 6 \t (Epoch done in 3097 sec)\n",
      "Loss on train    = 0.00145\n",
      "Accuracy on test = 0.76105\n",
      "\n",
      "EPOCH: 7 \t (Epoch done in 3096 sec)\n",
      "Loss on train    = 0.00045\n",
      "Accuracy on test = 0.76285\n",
      "\n",
      "EPOCH: 8 \t (Epoch done in 3088 sec)\n",
      "Loss on train    = 0.00013\n",
      "Accuracy on test = 0.76510\n",
      "\n",
      "EPOCH: 9 \t (Epoch done in 3116 sec)\n",
      "Loss on train    = 0.00005\n",
      "Accuracy on test = 0.76060\n",
      "\n",
      "EPOCH: 10 \t (Epoch done in 3082 sec)\n",
      "Loss on train    = 0.00002\n",
      "Accuracy on test = 0.75969\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "train_loss = []\n",
    "test_metrics = []\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    t = time.time()\n",
    "    siamese_model.train()\n",
    "    epoch_loss = []\n",
    "\n",
    "    for data in transform_triplet(train_triplet, batch_size=batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        anchor, positive, negative = data  \n",
    "        ap_distance, an_distance = siamese_model(anchor, positive, negative)\n",
    "        loss = triplet_loss(ap_distance, an_distance)   \n",
    "        loss.backward()  \n",
    "        optimizer.step() \n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "    epoch_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    print(f\"\\nEPOCH: {epoch} \\t (Epoch done in {int(time.time()-t)} sec)\")\n",
    "    print(f\"Loss on train    = {epoch_loss:.5f}\")\n",
    "\n",
    "    \n",
    "    metric = accuracy_model(siamese_model, test_triplet, batch_size=batch_size)\n",
    "    test_metrics.append(metric)\n",
    "    accuracy = metric[0]\n",
    "\n",
    "\n",
    "torch.save(siamese_model.state_dict(), \"siamese_model-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_metrics\u001b[49m]\n\u001b[1;32m      3\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# plot 1 train loss\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "accuracies = [item[0] for item in test_metrics]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# plot 1 train loss\n",
    "ax1.plot(train_loss, label='Train Loss')\n",
    "ax1.set_title('Model Train Loss Over Epochs')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Train loss')\n",
    "ax1.set_xticks(range(len(train_loss)))\n",
    "ax1.set_xticklabels(range(1, len(train_loss) + 1))\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# plot 2 accuracy on test\n",
    "ax2.plot(accuracies, label='Accuracy')\n",
    "ax2.set_title('Model Accuracy on Testset Over Epochs')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_xticks(range(len(accuracies)))\n",
    "ax2.set_xticklabels(range(1, len(accuracies) + 1))\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
